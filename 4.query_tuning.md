# 查询调优

- 在开始下面步骤之前，执行下面这条语句来关闭缓存，这样你就能知道真实的请求情况。

```
ALTER USER [Your-Redshift_User] SET enable_result_cache_for_session TO false;
```


## 选择性过滤

Redshift 在查询时可以使用索引进行加速。我们在载入数据时设置了 `ORDERKEY (o_orderdate)`，针对该索引字段做条件查询时，效率会更高。

下面这个查询是针对索引的。

```
SELECT count(1), sum(o_totalprice)
FROM orders
WHERE o_orderdate between '1992-07-05' and '1992-07-07';
```

下面这个则不是。

```
SELECT count(1), sum(o_totalprice)
FROM orders
where o_orderkey < 600001;
```

二者扫描的数据量类似，但效率差别很大。通过下面这个语句可以查看两个语句的实际执行时间。

```
SELECT query, TRIM(querytxt) as SQL, starttime, endtime, DATEDIFF(microsecs, starttime, endtime) AS duration
FROM STL_QUERY
WHERE TRIM(querytxt) LIKE '%orders%'
ORDER BY starttime DESC
LIMIT 4;
```

其中的 `duration` 展示了两个语句的执行时间差异，单位为微妙。

- ❗️如果你的集群配置不高则会很明显，如果配置高则差异不明显。


## 数据压缩

Redshift 使用列式存储，并且会针对列中的数据进行压缩以高效地读取和统计数据。

使用下面的语句可以查看某个表的所有列的压缩算法。

```
SELECT tablename, "column", encoding
FROM pg_table_def
WHERE schemaname = 'public' AND tablename = 'lineitem'
```

这个表的数据导入时，我们让 Redshift 自动按数据类型选择了算法。

下面我们测试下如果没有压缩的效果。用下面的语句创建一个新的 `lineitem` 表，然后使用原始格式（`RAW`）存储不做压缩。

```
DROP TABLE IF EXISTS lineitem_v1;
CREATE TABLE lineitem_v1 (
  L_ORDERKEY bigint NOT NULL ENCODE RAW       ,
  L_PARTKEY bigint ENCODE RAW                 ,
  L_SUPPKEY bigint ENCODE RAW                 ,
  L_LINENUMBER integer NOT NULL ENCODE RAW    ,
  L_QUANTITY decimal(18,4) ENCODE RAW         ,
  L_EXTENDEDPRICE decimal(18,4) ENCODE RAW    ,
  L_DISCOUNT decimal(18,4) ENCODE RAW         ,
  L_TAX decimal(18,4) ENCODE RAW              ,
  L_RETURNFLAG varchar(1) ENCODE RAW          ,
  L_LINESTATUS varchar(1) ENCODE RAW          ,
  L_SHIPDATE date ENCODE RAW                  ,
  L_COMMITDATE date ENCODE RAW                ,
  L_RECEIPTDATE date ENCODE RAW               ,
  L_SHIPINSTRUCT varchar(25) ENCODE RAW       ,
  L_SHIPMODE varchar(10) ENCODE RAW           ,
  L_COMMENT varchar(44) ENCODE RAW
)
DISTKEY (L_ORDERKEY)
SORTKEY (L_RECEIPTDATE);

INSERT INTO lineitem_v1
SELECT * FROM lineitem;

ANALYZE lineitem_v1;
```

- ❗️这个操作比较耗时。

使用下面的语句来对比两个表的存储空间。

```
SELECT
  CAST(d.attname AS CHAR(50)),
  SUM(CASE WHEN CAST(d.relname AS CHAR(50)) = 'lineitem'
THEN b.size_in_mb ELSE 0 END) AS size_in_mb,
  SUM(CASE WHEN CAST(d.relname AS CHAR(50)) = 'lineitem_v1'
THEN b.size_in_mb ELSE 0 END) AS size_in_mb_v1,
  SUM(SUM(CASE WHEN CAST(d.relname AS CHAR(50)) = 'lineitem'
THEN b.size_in_mb ELSE 0 END)) OVER () AS total_mb,
  SUM(SUM(CASE WHEN CAST(d.relname AS CHAR(50)) = 'lineitem_v1'
THEN b.size_in_mb ELSE 0 END)) OVER () AS total_mb_v1
FROM (
  SELECT relname, attname, attnum - 1 AS colid
  FROM pg_class t
  INNER JOIN pg_attribute a ON a.attrelid = t.oid
  WHERE t.relname LIKE 'lineitem%') d
INNER JOIN (
  SELECT name, col, MAX(blocknum) AS size_in_mb
  FROM stv_blocklist b
  INNER JOIN stv_tbl_perm p ON b.tbl=p.id
  GROUP BY name, col) b
ON d.relname = b.name AND d.colid = b.col
GROUP BY d.attname
ORDER BY d.attname;
```

其中：

- `size_in_mb` = 某个表的大小
- `total_mb` = 整个数据库的大小

## 查询规划

使用 `EXPLAIN` 语句可以查看 Redshift 的查询规划。

这个语句的意思是：统计不同产品（机器、汽车、家具等等）在 1992 年的订单数量、售出数量以及总价。在这里面并没有实际用到买家信息，只是作为 `JOIN` 的演示。

```
EXPLAIN
SELECT c_mktsegment,COUNT(o_orderkey) AS orders_count, SUM(l_quantity) AS quantity, SUM(l_extendedprice) AS extendedprice
FROM lineitem
JOIN orders ON l_orderkey = o_orderkey
JOIN customer c ON o_custkey = c_custkey
WHERE l_commitdate BETWEEN '1992-01-01T00:00:00Z' AND '1992-12-31T00:00:00Z'
GROUP BY c_mktsegment;
```

得到结果。

```
XN HashAggregate (cost=43540757.08..43540757.12 rows=5 width=44)
-> XN Hash Join DS_DIST_ALL_NONE (cost=4831606.11..43136503.89 rows=40425319 width=44)
Hash Cond: ("outer".o_custkey = "inner".c_custkey)
-> XN Hash Join DS_DIST_NONE (cost=4644106.11..36397222.70 rows=40311659 width=39)
Hash Cond: ("outer".o_orderkey = "inner".l_orderkey)
-> XN Seq Scan on orders (cost=0.00..760000.00 rows=76000000 width=16)
-> XN Hash (cost=4545123.36..4545123.36 rows=39593101 width=31)
-> XN Seq Scan on lineitem (cost=0.00..4545123.36 rows=39593101 width=31)
Filter: ((l_commitdate <= '1992-12-31'::date) AND (l_commitdate >= '1992-01-01'::date))
-> XN Hash (cost=150000.00..150000.00 rows=15000000 width=21)
```

结果从下往上看。

- 成本相关
	- `cost` = 是这个操作的相对成本，用一个数字来表示；`..` 前面的数字代表返回第一行结果所需的成本，后面是完成整个操作所需的成本
	- `rows` = 是这个操作会返回的行数估计
	- `width` = 每一行的平均宽度估计，以字节为单位
- 查询规划
	- `Hash` = 为内表创建 Hash 表然后 `JOIN` 外表
	- `Hash Join` = 为外表创建 Hash 然后 `JOIN` 内表
	- `Seq Scan` = 全表扫描，比如 `lineitem` 的 `l_commitdate` 没有建索引，只能权标扫描
- 数据再分布策略
	- `DS_DIST_ALL_NONE` = 无需再分布数据，数据在每个节点都有一份
	  - `customer` 表使用了 `DISTSTYLE ALL`
	- `DS_NONE` = 无需再分布数据，需要 `JOIN` 的数据正好分布在同一个节点
	  - `lineitem` 和 `order` 的 `DISTKEY` 都是 `orderkey`，所以正好都分布在一起
	- 这两种是最优化的再分布策略，因为不用转移数据就可以直接在节点进行操作

下面我们创建一个新的 `customer` 表。

```
DROP TABLE IF EXISTS customer_v1;
CREATE TABLE customer_v1
DISTKEY (c_custkey) as
SELECT * FROM customer;
```

这次不在每个节点复制一份完整的表，而是使用 `c_custkey` 来把数据分布到不同的节点。

然后我们再查看之前的查询会如何规划。

```
EXPLAIN
SELECT c_mktsegment,COUNT(o_orderkey) AS orders_count, sum(l_quantity) as quantity, sum (l_extendedprice) as extendedprice
FROM lineitem
JOIN orders on l_orderkey = o_orderkey
JOIN customer_v1 c on o_custkey = c_custkey
WHERE l_commitdate between '1992-01-01T00:00:00Z' and '1992-12-31T00:00:00Z'
GROUP BY c_mktsegment;
```

得到结果。


```
XN HashAggregate (cost=4200043540757.08..4200043540757.12 rows=5 width=43)
-> XN Hash Join DS_BCAST_INNER (cost=4831606.11..4200043136503.89 rows=40425319 width=43)
Hash Cond: ("outer".o_custkey = "inner".c_custkey)
-> XN Hash Join DS_DIST_NONE (cost=4644106.11..36397222.70 rows=40311659 width=39)
Hash Cond: ("outer".o_orderkey = "inner".l_orderkey)
-> XN Seq Scan on orders (cost=0.00..760000.00 rows=76000000 width=16)
-> XN Hash (cost=4545123.36..4545123.36 rows=39593101 width=31)
-> XN Seq Scan on lineitem (cost=0.00..4545123.36 rows=39593101 width=31)
Filter: ((l_commitdate <= '1992-12-31'::date) AND (l_commitdate >= '1992-01-01'::date))
-> XN Hash (cost=150000.00..150000.00 rows=15000000 width=20)
```

可以看到主要的变化是最外层的 `JOIN`。

- `DS_BCAST_INNER` = 把内表复制一份到所有节点，然后再进行计算，实际上是实时地做了 `DISTSTYLE ALL` 的事

可以执行感受下差别。如果实例选择较大或者节点较少，差别可能不明显。

```
SELECT c_mktsegment,COUNT(o_orderkey) AS orders_count, sum(l_quantity) as quantity, sum (l_extendedprice) as extendedprice
FROM lineitem
JOIN orders on l_orderkey = o_orderkey
JOIN customer_v1 c on o_custkey = c_custkey
WHERE l_commitdate between '1992-01-01T00:00:00Z' and '1992-12-31T00:00:00Z'
GROUP BY c_mktsegment;
```

再创建一个 `orders` 表，使用 `DISTSTYLE EVEN`，即把数据按顺序均匀分散到不同节点上。

```
DROP TABLE IF EXISTS orders_v1;
CREATE TABLE orders_v1
DISTSTYLE EVEN as
SELECT * FROM orders;
```

再查看查询规划。

```
EXPLAIN
SELECT c_mktsegment,COUNT(o_orderkey) AS orders_count, sum(l_quantity) as quantity, sum (l_extendedprice) as extendedprice
FROM lineitem
JOIN orders_v1 on l_orderkey = o_orderkey
JOIN customer_v1 c on o_custkey = c_custkey
WHERE l_commitdate between '1992-01-01T00:00:00Z' and '1992-12-31T00:00:00Z'
GROUP BY c_mktsegment;
```

得到结果。


```
XN HashAggregate (cost=13320043540757.08..13320043540757.12 rows=5 width=43)
-> XN Hash Join DS_BCAST_INNER (cost=4831606.11..13320043136503.89 rows=40425319 width=43)
Hash Cond: ("outer".o_custkey = "inner".c_custkey)
-> XN Hash Join DS_DIST_OUTER (cost=4644106.11..9120036397222.70 rows=40311659 width=39)
Outer Dist Key: orders_v1.o_orderkey
Hash Cond: ("outer".o_orderkey = "inner".l_orderkey)
-> XN Seq Scan on orders_v1 (cost=0.00..760000.00 rows=76000000 width=16)
-> XN Hash (cost=4545123.36..4545123.36 rows=39593101 width=31)
-> XN Seq Scan on lineitem (cost=0.00..4545123.36 rows=39593101 width=31)
Filter: ((l_commitdate <= '1992-12-31'::date) AND (l_commitdate >= '1992-01-01'::date))
```

可以看到又多了一个 `DS_DIST_OUTER`。

- `DS_DIST_OUTER` = 把外表分散到所有节点。

感受下。

```
SELECT c_mktsegment,COUNT(o_orderkey) AS orders_count, sum(l_quantity) as quantity, sum (l_extendedprice) as extendedprice
FROM lineitem
JOIN orders_v1 on l_orderkey = o_orderkey
JOIN customer_v1 c on o_custkey = c_custkey
WHERE l_commitdate between '1992-01-01T00:00:00Z' and '1992-12-31T00:00:00Z'
GROUP BY c_mktsegment;
```









