# Redshift Spectrum

## 概要

- 从桶中复制部分数据到 Redshift 集群
- 剩余部分作为外表，用 Glue 爬虫把表结构爬下来
- 把集群中的数据和外表中的数据做 `JOIN`


## 导入本地数据表

开始之前，重新打开缓存。

```
ALTER USER [Your-Redshift_User] SET enable_result_cache_for_session to true;
```

在 Redshift 中创建表。DAS 指的是 Direct-Attached Storage，即在 Redshift 集群中存储的数据。

```
CREATE SCHEMA workshop_das;

CREATE TABLE workshop_das.green_201601_csv
(
  vendorid                VARCHAR(4),
  pickup_datetime         TIMESTAMP,
  dropoff_datetime        TIMESTAMP,
  store_and_fwd_flag      VARCHAR(1),
  ratecode                INT,
  pickup_longitude        FLOAT4,
  pickup_latitude         FLOAT4,
  dropoff_longitude       FLOAT4,
  dropoff_latitude        FLOAT4,
  passenger_count         INT,
  trip_distance           FLOAT4,
  fare_amount             FLOAT4,
  extra                   FLOAT4,
  mta_tax                 FLOAT4,
  tip_amount              FLOAT4,
  tolls_amount            FLOAT4,
  ehail_fee               FLOAT4,
  improvement_surcharge   FLOAT4,
  total_amount            FLOAT4,
  payment_type            VARCHAR(4),
  trip_type               VARCHAR(4)
)
DISTSTYLE EVEN
SORTKEY (passenger_count,pickup_datetime);
```

用 `COPY` 从 S3 桶中复制数据，把 `[Your-Redshift_Role_Arn]` 换成你实际的角色 ARN。这个数据集包括的是 2016 年 1 月，纽约市出租车的运单数据。

```
COPY workshop_das.green_201601_csv
FROM 's3://us-west-2.serverless-analytics/NYC-Pub/green/green_tripdata_2016-01.csv'
IAM_ROLE '[Your-Redshift_Role_Arn]'
DATEFORMAT 'auto'
IGNOREHEADER 1
DELIMITER ','
IGNOREBLANKLINES
REGION 'us-west-2'
;
```

`COPY` 命令支持从不同区来导入数据，如果 Redshift 和桶不在一个区，需要用 `REGION` 指明区域。

我们来看下导入了多少条数据。

```
SELECT COUNT(1) FROM workshop_das.green_201601_csv;
--1445285
```

2016 年 1 月纽约市经历了[有史以来最大规模的暴风雪](https://www.nbcnewyork.com/news/local/nyc-new-york-city-blizzard-biggest-ever-january-23-2016/831660/)，出租车运单数量极低。我们用下面这条语句把这一天找出来。

```
SELECT TO_CHAR(pickup_datetime, 'YYYY-MM-DD'), COUNT(*)
FROM workshop_das.green_201601_csv
GROUP BY 1
ORDER BY 2;
```

## 用 Glue 爬取外部表的结构

外部表以文件形式存储在 S3 上。要查询外部表，我们首先得让 Redshift 知道外部表的分区（目录）结构，以及这些文件的数据格式。

我们可以手动创建这样的表，也可以用 Glue Crawler 来爬取数据。爬虫会遍历我们选择的 S3 目录，然后遍历读取所有文件，并且尝试从目录结构来判断分区，从文件内容来判断数据字段的定义。

我们可以让 Crawler 定时爬取，方便在新分区和数据增加时可以定时纳入。也可以手动调用，只在需要的时候爬取。

表的结构会存在 Glue Data Catalog 内。

由于 Glue 是 AWS 服务，所以 Redshift、Athena、EMR 等都可以访问它，把它作为共享的外部表格定义。

这一步我们需要打开 Glue 控制台，找到 Crawlers，创建爬虫。在这个过程中，我们需要创建一个新的数据库 `spectrumdb`，然后选择 S3 作为数据源，选择 `On Demand` 即按需运行。S3 数据源的地址如下：

```
s3://us-west-2.serverless-analytics/canonical/NY-Pub
```

这是一个公开地址，可以直接使用命令行查看其内容。

运行爬虫之后，我们会在 `spectrumdb` 下看到一个 `ny_pub` 表，表内有 28.7 亿条数据。 

## 创建 Redshift 外部表并查询

现在表的信息已经在 Glue Data Catalog 内，但是 Redshift 还不知道它的存在。我们需要在 Redshift 内也创建一个外部表，对接 Glue 中的这个表。

```
CREATE EXTERNAL SCHEMA adb305
FROM DATA CATALOG DATABASE 'spectrumdb'
IAM_ROLE '[Your-Redshift_Role_Arn]'
CREATE EXTERNAL DATABASE IF NOT EXISTS;
```

- `EXTERNAL SCHEMA` = 这是一个外部表，不是 DAS
- `FROM DATA CATALOG` = 表的定义和原信息在 Glue Data Catalog 内

执行下面这个语句，这次是从外部表来查询。

```
SELECT TO_CHAR(pickup_datetime, 'YYYY-MM-DD'), COUNT(*)
FROM adb305.ny_pub
WHERE YEAR = 2016 AND Month = 01
GROUP BY 1
ORDER BY 2;
```

❗️如果一开始 Redshift 不是在 `us-west-2` 创建，你会遇到如下错误：`ERROR: Spectrum Scan Error: S3ServiceException:The S3 bucket addressed by the query is in a different region from this cluster.,Status 301,Error PermanentRedirect`。这是因为 Redshift Spectrum 只能查询本区的 S3 上的数据。

这次，查询时间会稍微长一些，因为 Redshift 会去扫描 S3 上的文件。

## 联合本地和外部表

接下来我们要导入

把 2016 年 1 月并且 `type` 是 `green` 的数据导入一个本地表。

```
CREATE TABLE workshop_das.taxi_201601 AS
SELECT * FROM adb305.ny_pub
WHERE year = 2016 AND month = 1 AND type = 'green';
```

使用 `CREATE TABLE AS`（`CTAS`）语句创建的表，Redshift 会根据其字段自动选择压缩算法。

用下面这个语句可以看到字段压缩算法和节省空间。

```
ANALYZE COMPRESSION workshop_das.taxi_201601
```

把剩余 `type` 不是 `green` 的数据补齐。

```
INSERT INTO workshop_das.taxi_201601 (
  SELECT *
  FROM adb305.ny_pub
  WHERE year = 2016 AND month = 1 AND type != 'green'
);
```

接下来我们去掉外部表中的重复数据。

```
ALTER TABLE adb305.ny_pub DROP PARTITION(year=2016, month=1, type='fhv');
ALTER TABLE adb305.ny_pub DROP PARTITION(year=2016, month=1, type='green');
ALTER TABLE adb305.ny_pub DROP PARTITION(year=2016, month=1, type='yellow');
```

创建一个结合了内外表的视图。

```
CREATE VIEW adb305_view_NYTaxiRides AS
  SELECT * FROM workshop_das.taxi_201601
  UNION ALL
  SELECT * FROM adb305.ny_pub
WITH NO SCHEMA BINDING;
```

视图像是一个指针表，不会把数据落盘，每次查询视图，都会即时运行视图内的 `SELECT` 语句。

- `WITH NO SCHEMA BINDING` = 创建后约束视图，即在创建时不检查视图内的表字段是否一致有效。当视图内包含外部表时，只能使用后约束视图。

接下来先查询一下这个视图。查询 2016 年 1 月乘客为 4 人的运单。

```
EXPLAIN
SELECT year, month, type, COUNT(*)
FROM adb305_view_NYTaxiRides
WHERE year = 2016 AND month IN (1) AND passenger_count = 4
GROUP BY 1,2,3 ORDER BY 1,2,3;
```

再加入 2016 年 2 月的数据。这个数据只在 S3 上有。

```
EXPLAIN
SELECT year, month, type, COUNT(*)
FROM adb305_view_NYTaxiRides
WHERE year = 2016 AND month IN (1,2) AND passenger_count = 4
GROUP BY 1,2,3 ORDER BY 1,2,3;
```

这个查询会消耗多一些时间。

再统计 2016 年 1、2 月中不同载客数的运单。

```
EXPLAIN
SELECT passenger_count, COUNT(*)
FROM adb305.ny_pub
WHERE year = 2016 AND month IN (1,2)
GROUP BY 1 ORDER BY 1;
```

统计 2016 年 1、2 月不同出租车公司的运单。

```
EXPLAIN
SELECT type, COUNT(*)
FROM adb305.ny_pub
WHERE year = 2016 AND month IN (1,2)
GROUP BY 1 ORDER BY 1 ;
```

或者更激进的，统计有记录以来，不同出租车公司的运单。注意这个查询会非常消耗时间。

```
SELECT type, COUNT(*)
FROM adb305.ny_pub
GROUP BY 1 ORDER BY 1 ;
```

外部表实际上就是数据湖中相对规整的部分，而 Redshift 的内部表则是数仓。在 Redshift 内直接联合外部表和内部表进行查询和统计，我们就实现了「湖仓一体」。

















