# 导入数据

## 概要

- 连接到 Redshift 集群，需要先创建连接（实际上是创建连接参数组）
- 默认数据库是 `dev`，要创建连接需要先选择数据库，但是又要连接后才能创建数据库，所以需要用一个默认数据库
- 数据格式
	- 支持导入 [CSV](https://docs.aws.amazon.com/redshift/latest/dg/copy-parameters-data-format.html#copy-csv)、[JSON](https://docs.aws.amazon.com/redshift/latest/dg/copy-usage_notes-copy-from-json.html)
	- 支持导入 [Arvo](https://docs.aws.amazon.com/redshift/latest/dg/copy-parameters-data-format.html#copy-avro)
	- 支持导入 [Parquet、ORC](https://docs.aws.amazon.com/redshift/latest/dg/copy-usage_notes-copy-from-columnar.html)

## 连接到集群和数据库

1. 执行语句之前必须先连接到集群
2. 可以直接在 Redshift 控制台界面直接创建连接，一个连接对应一个数据库
	- 控制台的查询语句编辑器是跨数据库的，使用 `database.schema.table` 的形式可以直接访问其他数据库内的数据

## 创建数据表

1. 创建如下数据表，这些表参考了 TPC（Transaction Processing Council）Benchmark 的标准。

```
DROP TABLE IF EXISTS partsupp;
DROP TABLE IF EXISTS lineitem;
DROP TABLE IF EXISTS supplier;
DROP TABLE IF EXISTS part;
DROP TABLE IF EXISTS orders;
DROP TABLE IF EXISTS customer;
DROP TABLE IF EXISTS nation;
DROP TABLE IF EXISTS region;

CREATE TABLE region (
  R_REGIONKEY bigint NOT NULL,
  R_NAME varchar(25),
  R_COMMENT varchar(152))
diststyle all;

CREATE TABLE nation (
  N_NATIONKEY bigint NOT NULL,
  N_NAME varchar(25),
  N_REGIONKEY bigint,
  N_COMMENT varchar(152))
diststyle all;

create table customer (
  C_CUSTKEY bigint NOT NULL,
  C_NAME varchar(25),
  C_ADDRESS varchar(40),
  C_NATIONKEY bigint,
  C_PHONE varchar(15),
  C_ACCTBAL decimal(18,4),
  C_MKTSEGMENT varchar(10),
  C_COMMENT varchar(117))
diststyle all;

create table orders (
  O_ORDERKEY bigint NOT NULL,
  O_CUSTKEY bigint,
  O_ORDERSTATUS varchar(1),
  O_TOTALPRICE decimal(18,4),
  O_ORDERDATE Date,
  O_ORDERPRIORITY varchar(15),
  O_CLERK varchar(15),
  O_SHIPPRIORITY Integer,
  O_COMMENT varchar(79))
distkey (O_ORDERKEY)
sortkey (O_ORDERDATE);

create table part (
  P_PARTKEY bigint NOT NULL,
  P_NAME varchar(55),
  P_MFGR  varchar(25),
  P_BRAND varchar(10),
  P_TYPE varchar(25),
  P_SIZE integer,
  P_CONTAINER varchar(10),
  P_RETAILPRICE decimal(18,4),
  P_COMMENT varchar(23))
diststyle all;

create table supplier (
  S_SUPPKEY bigint NOT NULL,
  S_NAME varchar(25),
  S_ADDRESS varchar(40),
  S_NATIONKEY bigint,
  S_PHONE varchar(15),
  S_ACCTBAL decimal(18,4),
  S_COMMENT varchar(101))
diststyle all;                                                              

create table lineitem (
  L_ORDERKEY bigint NOT NULL,
  L_PARTKEY bigint,
  L_SUPPKEY bigint,
  L_LINENUMBER integer NOT NULL,
  L_QUANTITY decimal(18,4),
  L_EXTENDEDPRICE decimal(18,4),
  L_DISCOUNT decimal(18,4),
  L_TAX decimal(18,4),
  L_RETURNFLAG varchar(1),
  L_LINESTATUS varchar(1),
  L_SHIPDATE date,
  L_COMMITDATE date,
  L_RECEIPTDATE date,
  L_SHIPINSTRUCT varchar(25),
  L_SHIPMODE varchar(10),
  L_COMMENT varchar(44))
distkey (L_ORDERKEY)
sortkey (L_RECEIPTDATE);

create table partsupp (
  PS_PARTKEY bigint NOT NULL,
  PS_SUPPKEY bigint NOT NULL,
  PS_AVAILQTY integer,
  PS_SUPPLYCOST decimal(18,4),
  PS_COMMENT varchar(199))
diststyle even;
```

- `DISTSTYLE` 指的是数据分布方式
	- `ALL` = 每个节点存完整数据
	- `EVEN` = 随机把数据分配到不同的节点
	- `KEY` = 按某个字段，值相同的放一个节点
	- `AUTO` = 根据表大小自动选择


## 导入数据

1. 使用下列 `COPY` 语句来从公用桶中复制数据
	- ❗️把 `[Your-Redshift-Role]` 替换成你之前创建的角色的 ARN，比如 `arn:aws:iam::123456789012:role/redshift-full-access`
	- ❗️如果选择的机型较小（如 `ra3.xlplus`），此项操作需要耗时数十分钟

```
COPY region FROM 's3://redshift-immersionday-labs/data/region/region.tbl.lzo'
iam_role '[Your-Redshift-Role]'
region 'us-west-2' lzop delimiter '|' COMPUPDATE PRESET;

COPY nation FROM 's3://redshift-immersionday-labs/data/nation/nation.tbl.'
iam_role '[Your-Redshift-Role]'
region 'us-west-2' lzop delimiter '|' COMPUPDATE PRESET;

copy customer from 's3://redshift-immersionday-labs/data/customer/customer.tbl.'
iam_role '[Your-Redshift-Role]'
region 'us-west-2' lzop delimiter '|' COMPUPDATE PRESET;

copy orders from 's3://redshift-immersionday-labs/data/orders/orders.tbl.'
iam_role '[Your-Redshift-Role]'
region 'us-west-2' lzop delimiter '|' COMPUPDATE PRESET;

copy part from 's3://redshift-immersionday-labs/data/part/part.tbl.'
iam_role '[Your-Redshift-Role]'
region 'us-west-2' lzop delimiter '|' COMPUPDATE PRESET;

copy supplier from 's3://redshift-immersionday-labs/data/supplier/supplier.json' manifest
iam_role '[Your-Redshift-Role]'
region 'us-west-2' lzop delimiter '|' COMPUPDATE PRESET;

copy lineitem from 's3://redshift-immersionday-labs/data/lineitem-part/'
iam_role '[Your-Redshift-Role]'
region 'us-west-2' gzip delimiter '|' COMPUPDATE PRESET;

copy partsupp from 's3://redshift-immersionday-labs/data/partsupp/partsupp.tbl.'
iam_role '[Your-Redshift-Role]'
region 'us-west-2' lzop delimiter '|' COMPUPDATE PRESET;
```

- 数据统计和 `ra3.xlplus` 下的载入时间
	- REGION (5 rows) - 20s
	- NATION (25 rows) - 20s
	- CUSTOMER (15M rows) – 3m
	- ORDERS - (76M rows) - 1m
	- PART - (20M rows) - 4m
	- SUPPLIER - (1M rows) - 1m
	- LINEITEM - (600M rows) - 13m
	- PARTSUPPLIER - (80M rows) 3m
- 这里展示了多种载入方式
	- 直接用文件名
	- 用 `tbl.` 这种 `.` 结尾的方式会用通配符的方式载入所有数据文件
	- 用 `line-item-part/` 这种 `/` 结尾的方式会载入该前缀（文件夹）下所有的数据文件
	- 用 `.json MANIFEST` 的方式，在 JSON 文件中包含所有的数据文件路径
- `COMPUPDATE` 指的是[如何确定压缩算法](https://docs.aws.amazon.com/redshift/latest/dg/copy-parameters-data-load.html#copy-compupdate)
	- 完全不写这条语句 = 只在目标表是空的而且也没有设置压缩算法时，由 Redshift 按列数据类型来设置压缩算法
	- `PRESET` = 只要目标表是空的，即便已经设置了压缩算法，也由 Redshift 按列数据类型来设置压缩算法
	- `ON` 或者只写 `COMPUPDATE` 没有参数 = Redshift 按照数据取样来确定压缩算法，可能会覆盖原来的算法
- `STATUPDATE` 指的是是否自动更新表的统计数据
	- 不写参数 = 如果表是新的则更新
	- `ON` = 总是更新，如果新加数据则增量更新，要求导数据的用户有超级用户权限或者是表主人
	- `OFF` = 不更新
- 运行 `ANALYZE tablename` 语句也可以更新表统计数据，但通常你不需要手动运行，Redshift 会自动在后台更新表统计数据
	- 如果表已经有统计数据并且后续未更新，Redshift 就不会实际运行 `ANALYZE` 语句即便用户手动提交该语句
- `NOLOAD` = 演练，不载入数据只验证格式
	- 用 `SELECT * FROM stl_load_errors;` 查看载入过程中的错误

## 清理表

- Redshift 中的 `UPDATE` 操作实际上是删除一行并且新增一行
- Redshift 更新和删除大量数据时不会立刻就回收存储空间
- 用下列语句可以回收删除的空间

```
VACUUM DELETE ONLY orders;
```

- 参数
	- `DELETE ONLY` = 回收删除之后的空间
	- `SORT ONLY` = 给表做排序但是不回收空间，如果表已经是 95% 排好序则 Redshift 不会再继续排序以提升效率
	- `FULL` = 两个都做







